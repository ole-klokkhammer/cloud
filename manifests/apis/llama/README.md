# llama.cpp
https://github.com/ggml-org/llama.cpp/blob/master/README.md

## setup
* sudo zfs create -o quota=15G k3s-temp/llama  
* cd /k3s-temp/llama
* wget https://huggingface.co/gabriellarson/Phi-mini-MoE-instruct-GGUF/resolve/main/Phi-mini-MoE-instruct-Q8_0.gguf
* ...



## commands
radeontop


## ROCm??
https://github.com/ROCm/ROCm/issues/1713
https://www.techpowerup.com/forums/threads/rocm-os.333072/